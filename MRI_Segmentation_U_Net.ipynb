{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MRI_Segmentation_U-Net.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FalseFeint/MertsMinions/blob/main/MRI_Segmentation_U_Net.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fekwqJEDtat"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "#                                 _     ___                        \n",
        "#    __    __ _   _ __    ___    | |   / __|  __ _    ___    ___   \n",
        "#   / _|  / _` | | '  \\  / -_)   | |  | (__  / _` |  (_-<   / -_)  \n",
        "#   \\__|_ \\__,_| |_|_|_| \\___|  _|_|_  \\___| \\__,_|  /__/_  \\___|  \n",
        "# _|\"\"\"\"\"_|\"\"\"\"\"_|\"\"\"\"\"_|\"\"\"\"\"_|\"\"\"\"\"_|\"\"\"\"\"_|\"\"\"\"\"_|\"\"\"\"\"_|\"\"\"\"\"| \n",
        "# \"`-0-0-\"`-0-0-\"`-0-0-\"`-0-0-\"`-0-0-\"`-0-0-\"`-0-0-\"`-0-0-\"`-0-0-' \n",
        "\n",
        "\"\"\"\n",
        "** camelCase!!!!!! **\n",
        "\n",
        "i = int\n",
        "dbl = double\n",
        "flt = float\n",
        "ten = tensor\n",
        "arr = array\n",
        "iArr = int array\n",
        "char = character\n",
        "str = string\n",
        "dict = dictionary\n",
        "lst = list\n",
        "mat = Matrix\n",
        "im = Image\n",
        "\"\"\"\n",
        "#   _____                              _____        _                 _   \n",
        "#  |  __ \\                            |  __ \\      | |               | |  \n",
        "#  | |__) _ __ ___   ___ ___ ___ ___  | |  | | __ _| |_ __ _ ___  ___| |_ \n",
        "#  |  ___| '__/ _ \\ / __/ _ / __/ __| | |  | |/ _` | __/ _` / __|/ _ | __|\n",
        "#  | |   | | | (_) | (_|  __\\__ \\__ \\ | |__| | (_| | || (_| \\__ |  __| |_ \n",
        "#  |_|   |_|  \\___/ \\___\\___|___|___/ |_____/ \\__,_|\\__\\__,_|___/\\___|\\__|\n",
        "\n",
        "#  _____        _                                                   _        _   _             \n",
        "#  |  __ \\      | |            /\\                                   | |      | | (_)            \n",
        "#  | |  | | __ _| |_ __ _     /  \\  _   _  __ _ _ __ ___   ___ _ __ | |_ __ _| |_ _  ___  _ __  \n",
        "#  | |  | |/ _` | __/ _` |   / /\\ \\| | | |/ _` | '_ ` _ \\ / _ \\ '_ \\| __/ _` | __| |/ _ \\| '_ \\ \n",
        "#  | |__| | (_| | || (_| |  / ____ \\ |_| | (_| | | | | | |  __/ | | | || (_| | |_| | (_) | | | |\n",
        "#  |_____/ \\__,_|\\__\\__,_| /_/    \\_\\__,_|\\__, |_| |_| |_|\\___|_| |_|\\__\\__,_|\\__|_|\\___/|_| |_|\n",
        "#                                         __/ |                                                \n",
        "#                                        |___/                                                 \n",
        "\n",
        "#   _______        _       _             \n",
        "#  |__   __|      (_)     (_)            \n",
        "#     | |_ __ __ _ _ _ __  _ _ __   __ _ \n",
        "#     | | '__/ _` | | '_ \\| | '_ \\ / _` |\n",
        "#     | | | | (_| | | | | | | | | | (_| |\n",
        "#     |_|_|  \\__,_|_|_| |_|_|_| |_|\\__, |\n",
        "#                                   __/ |\n",
        "#                                  |___/ \n",
        "\n",
        "\"\"\"\n",
        "TA: Can we follow an example closely (especially for baseline given that we \n",
        "are noobs)\n",
        "What should we include in the report?\n",
        "What are your thoughts on skullstripping?\n",
        "What are ways we can be innovative with our implementation?\n",
        "Any advice? Anything we should watch out for?\n",
        "How can we use the GPU in google colab?\n",
        "\n",
        "Professor said this:\n",
        "the expectation is that you will describe your problem, data and code that performs I/O and pre-processing.\n",
        "You can also offer a visual exploration of the data and show some results with simple baseline method,\n",
        "You can include preliminary results with implemented ML algorithm.\n",
        "\n",
        "The main text should NOT exceed 4 pages.\n",
        "\n",
        "\"\"\""
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQPefAMY-9UX"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fuqvstzy-rPf"
      },
      "source": [
        "#UNet\n",
        "Create UNet architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76FtFLpw-h3v"
      },
      "source": [
        "#   _    _ _   _      _   \n",
        "#  | |  | | \\ | |    | |  \n",
        "#  | |  | |  \\| | ___| |_ \n",
        "#  | |  | | . ` |/ _ | __|\n",
        "#  | |__| | |\\  |  __| |_ \n",
        "#   \\____/|_| \\_|\\___|\\__|\n",
        "\n",
        "class UNet(nn.Module): \n",
        "  def __init__(self, iInChannel=3, iOutChannel=1, iInFeatures=32):\n",
        "    super(UNet, self).__init__()\n",
        "\n",
        "    # TODO: See if we can reduce this to for-loop using eval\n",
        "    # TODO: Look into initializing all pool layers at once\n",
        "    iFeatures = iInFeatures\n",
        "\n",
        "    # Declare all our down blocks and max pool layers\n",
        "    self.downBlock1 = UNet._block(iInChannels, iFeatures, name=\"downBlock1\")\n",
        "    self.maxPool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "    self.downBlock2 = UNet._block(iFeatures, iFeatures * 2, name=\"downBlock2\")\n",
        "    self.maxPool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "    self.downBlock3 = UNet._block(iFeatures * 2, iFeatures * 4, name=\"downBlock3\")\n",
        "    self.maxPool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "    self.downBlock4 = UNet._block(iFeatures * 4, iFeatures * 8, name=\"downBlock4\")\n",
        "    self.maxPool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "    # Declare bottom of UNet\n",
        "    self.bottleneck = UNet._block(iFeatures * 8, features * 16, name=\"bottleneck\")\n",
        "\n",
        "    # TODO: See if we can reduce this to for-loop using eval\n",
        "    # TODO: Look into initializing all pool layers at once\n",
        "    # Declare up-blocks and up-convolutions\n",
        "    self.upconv4 = nn.ConvTranspose2d(\n",
        "        iFeatures * 16, iFeatures * 8, kernel_size=2, stride=2)\n",
        "    self.upBlock4 = UNet._block((iFeatures * 8) * 2, iFeatures * 8, name=\"upBlock4\")\n",
        "    \n",
        "    self.upconv3 = nn.ConvTranspose2d(\n",
        "        iFeatures * 8, iFeatures * 4, kernel_size=2, stride=2)\n",
        "    self.upBlock3 = UNet._block((iFeatures * 4) * 2, iFeatures * 4, name=\"upBlock3\")\n",
        "    \n",
        "    self.upconv2 = nn.ConvTranspose2d(\n",
        "        iFeatures * 4, iFeatures * 2, kernel_size=2, stride=2)\n",
        "    self.upBlock2 = UNet._block((iFeatures * 2) * 2, iFeatures * 2, name=\"upBlock2\")\n",
        "    \n",
        "    self.upconv1 = nn.ConvTranspose2d(\n",
        "        iFeatures * 2, iFeatures, kernel_size=2, stride=2)\n",
        "    self.upBlock1 = UNet._block(iFeatures * 2, iFeatures, name=\"upBlock1\")\n",
        "\n",
        "    self.conv = nn.Conv2d(\n",
        "        in_channels=features, out_channels=out_channels, kernel_size=1\n",
        "    )\n",
        "\n",
        "    # \n",
        "    def forward(self, x):\n",
        "        # Connect down blocks with max-pool layers\n",
        "        downBlock1 = self.downBlock1(x)\n",
        "        downBlock2 = self.downBlock2(self.maxPool1(downBlock1))\n",
        "        downBlock3 = self.downBlock3(self.maxPool2(downBlock2))\n",
        "        downBlock4 = self.downBlock4(self.maxPool3(downBlock3))\n",
        "\n",
        "        # Add bottleneck\n",
        "        bottleneck = self.bottleneck(self.pool4(downBlock4))\n",
        "\n",
        "        # Connect up blocks with up convolutions and skip connections\n",
        "        upBlock4 = self.upconv4(bottleneck)\n",
        "        upBlock4 = torch.cat((upBlock4, downBlock4), dim=1)\n",
        "        upBlock4 = self.upBlock4(upBlock4)\n",
        "        upBlock3 = self.upconv3(upBlock4)\n",
        "        upBlock3 = torch.cat((upBlock3, downBlock3), dim=1)\n",
        "        upBlock3 = self.upBlock3(upBlock3)\n",
        "        upBlock2 = self.upconv2(upBlock3)\n",
        "        upBlock2 = torch.cat((upBlock2, downBlock2), dim=1)\n",
        "        upBlock2 = self.upBlock2(upBlock2)\n",
        "        upBlock1 = self.upconv1(upBlock2)\n",
        "        upBlock1 = torch.cat((upBlock1, downBlock1), dim=1)\n",
        "        upBlock1 = self.upBlock1(upBlock1)\n",
        "        return torch.sigmoid(self.conv(upBlock1))\n",
        "\n",
        "\n",
        "    \"\"\" \n",
        "    This function is useful for blocking together convolutions, activations, \n",
        "    and max pooling for each \"meta-layer\" in our U-Net architecture \n",
        "\n",
        "    Convolution layers in this block have specified in channels, \n",
        "    features, a kernel size of 3, padding of 1 and no bias\n",
        "\n",
        "    We use batch normalization to reduce internal covariance\n",
        "\n",
        "    ReLU is used for non-linearity activation\n",
        "    \"\"\"\n",
        "    @staticmethod\n",
        "    def _block(in_channels, features, name):\n",
        "        return nn.Sequential(\n",
        "            OrderedDict(\n",
        "                [\n",
        "                    (\n",
        "                        name + \"conv1\",\n",
        "                        nn.Conv2d(\n",
        "                            in_channels=in_channels,\n",
        "                            out_channels=features,\n",
        "                            kernel_size=3,\n",
        "                            padding=1,\n",
        "                            bias=False,\n",
        "                        ),\n",
        "                    ),\n",
        "                    (name + \"norm1\", nn.BatchNorm2d(num_features=features)),\n",
        "                    (name + \"relu1\", nn.ReLU(inplace=True)),\n",
        "                    (\n",
        "                        name + \"conv2\",\n",
        "                        nn.Conv2d(\n",
        "                            in_channels=features,\n",
        "                            out_channels=features,\n",
        "                            kernel_size=3,\n",
        "                            padding=1,\n",
        "                            bias=False,\n",
        "                        ),\n",
        "                    ),\n",
        "                    (name + \"norm2\", nn.BatchNorm2d(num_features=features)),\n",
        "                    (name + \"relu2\", nn.ReLU(inplace=True)),\n",
        "                ]\n",
        "            )\n",
        "        )\n"
      ],
      "execution_count": 6,
      "outputs": []
    }
  ]
}